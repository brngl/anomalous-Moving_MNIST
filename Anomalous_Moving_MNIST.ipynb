{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anomalous Moving MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWw-wWgrqO2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Number:\n",
        "    def __init__(self, x, y, index, val):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.index = index\n",
        "        self.val = val\n",
        "\n",
        "    def get_x(self):\n",
        "        return self.x\n",
        "\n",
        "    def get_y(self):\n",
        "        return self.y\n",
        "\n",
        "    def get_index(self):\n",
        "        return self.index\n",
        "\n",
        "    def get_val(self):\n",
        "        return self.val\n",
        "\n",
        "    def distance(self, point):\n",
        "        # Euclidean distance beetween this point and other\n",
        "        import math\n",
        "        return math.sqrt(abs(self.get_x() - point.get_x()) + \n",
        "                         abs(self.get_y() - point.get_y()))\n",
        "\n",
        "    def encapsulate_numbers(legend_array, img_embed):\n",
        "        numbers = []\n",
        "        for i in range(len(legend_array)):\n",
        "            x_coo = img_embed[i,:][0]\n",
        "            y_coo = img_embed[i,:][1]\n",
        "            number = Number(x_coo, y_coo, i, legend_array[i])\n",
        "            numbers.append(number)\n",
        "        return numbers\n",
        "\n",
        "\n",
        "    def neighbours(numbers, same_digit, neighbourhood):\n",
        "        \"\"\"\n",
        "        # same_digit: a boolean. If False, it searches for different numbers \n",
        "                                who look like similar.\n",
        "                                If True, it searches for two similar \n",
        "                                representations of the same number.\n",
        "        # neighbourhood: a tuple. (min_distance, max_distance). \n",
        "                        min_distance xor max_distance can be None.\n",
        "        \"\"\"\n",
        "        min_distance = neighbourhood[0]\n",
        "        max_distance = neighbourhood[1]\n",
        "\n",
        "        if (min_distance == None and max_distance == None):\n",
        "            raise ValueError(\"Just one beetween min_distance and max_distance can be None\")\n",
        "\n",
        "        if (min_distance != None):\n",
        "            min_distance = neighbourhood[0]\n",
        "        else:\n",
        "            min_distance = 0\n",
        "\n",
        "        if (max_distance != None):\n",
        "            max_distance = neighbourhood[1]\n",
        "        else:\n",
        "            max_distance = 5\n",
        "\n",
        "        nbs = []\n",
        "        for num1 in numbers:\n",
        "            if (num1.get_index() % 1000 == 0):\n",
        "                print(num1.get_index())\n",
        "            for num2 in numbers:\n",
        "                same = True\n",
        "                if (not same_digit):\n",
        "                    same = num1.get_val() != num2.get_val()\n",
        "                else:\n",
        "                    same = num1.get_val() == num2.get_val()\n",
        "                if (num1.get_index() != num2.get_index() and\n",
        "                        min_distance <= num1.distance(num2) <= max_distance and\n",
        "                        same):\n",
        "                    nbs.append((num1, num2))\n",
        "        return nbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGmvJiIRfwXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "class AnomalousMovingMNIST:\n",
        "    '''\n",
        "    Args:\n",
        "    anom_frames: list of anomalous frame indexes that must appear in the sequence\n",
        "    num_anoms_per_frame: how many MNIST numbers have to be anomalous in an anomalous frame\n",
        "    n_clusters: number of clusters to perform K-Means. \n",
        "        More clusters imply smaller cluster size, more similarity between instances but less variety.\n",
        "        Less clusters imply bigger cluster size, less similarity between instances but more variety.\n",
        "    dataset = {training, test}: specifies whether the dataset should be created from the MNIST training set or test set\n",
        "    '''\n",
        "    def __init__(self, \n",
        "                 anom_frames,\n",
        "                 num_anoms_per_frame,\n",
        "                 type_of_anomaly,\n",
        "                 num_sequences=20000,\n",
        "                 shape=(64, 64),\n",
        "                 num_frames=30,\n",
        "                 original_size=28,\n",
        "                 nums_per_image=2,\n",
        "                 path_data = '',\n",
        "                 path_labels = '',\n",
        "                 path_tSNE = '',\n",
        "                 n_clusters = 30,\n",
        "                 dest='anomovingmnistdata',\n",
        "                 filetype='npz',\n",
        "                 dataset='test',):\n",
        "        if(not num_anoms_per_frame in [1,2]):\n",
        "            raise ValueError(\"num_anoms_per_frame must be 1 or 2\")\n",
        "        \n",
        "        if(not dataset in ['training', 'test']):\n",
        "            raise ValueError(\"possible values: {training, test}\")\n",
        "        \n",
        "        self.shape = shape\n",
        "        self.num_frames = num_frames\n",
        "        self.num_sequences = num_sequences\n",
        "        self.original_size = original_size\n",
        "        self.nums_per_image = nums_per_image\n",
        "        self.dest = dest\n",
        "        self.filetype = filetype\n",
        "        self.dataset = dataset\n",
        "        self.path_data = path_data\n",
        "        self.path_labels = path_labels\n",
        "        self.path_tSNE = path_tSNE\n",
        "        self.n_clusters = n_clusters\n",
        "        self.anom_frames = anom_frames\n",
        "        self.num_anoms_per_frame = num_anoms_per_frame\n",
        "        self.type_of_anomaly = type_of_anomaly\n",
        "\n",
        "    def get_mnist_path(self):\n",
        "        return self.mnist_path\n",
        "    \n",
        "    def arr_from_img(self, im, mean=0, std=1):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            im: Image\n",
        "            shift: Mean to subtract\n",
        "            std: Standard Deviation to subtract\n",
        "\n",
        "        Returns:\n",
        "            Image in np.float32 format, in width height channel format. With values in range 0,1\n",
        "            Shift means subtract by certain value. Could be used for mean subtraction.\n",
        "        '''\n",
        "        width, height = im.size\n",
        "        arr = im.getdata()\n",
        "        c = int(np.product(arr.size) / (width * height))\n",
        "\n",
        "        return (np.asarray(arr, dtype=np.float32).reshape((height, width, c)).transpose(2, 1, 0)) / std\n",
        "\n",
        "    def get_image_from_array(self, X, index, mean=0, std=1):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            X: Dataset of shape N x C x W x H\n",
        "            index: Index of image we want to fetch\n",
        "            mean: Mean to add\n",
        "            std: Standard Deviation to add\n",
        "        Returns:\n",
        "            Image with dimensions H x W x C or H x W if it's a single channel image\n",
        "        '''\n",
        "        ch, w, h = X.shape[1], X.shape[2], X.shape[3]\n",
        "        ret = (((X[index] + mean)) * std).reshape(ch, w, h).transpose(2, 1, 0)#.clip(0, 255).astype(np.uint8)\n",
        "        if ch == 1:\n",
        "            ret = ret.reshape(h, w)\n",
        "        return ret\n",
        "    \n",
        "\n",
        "    def get_image_from_array_blank(self, X, index, mean=0, std=1):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            X: Dataset of shape N x C x W x H\n",
        "            index: Index of image we want to fetch\n",
        "            mean: Mean to add\n",
        "            std: Standard Deviation to add\n",
        "        Returns:\n",
        "            Image with dimensions H x W x C or H x W if it's a single channel image\n",
        "        '''\n",
        "        ch, w, h = X.shape[1], X.shape[2], X.shape[3]\n",
        "        ret = (((X[index] + mean)) * std).reshape(ch, w, h).transpose(2, 1, 0)#.clip(0, 255).astype(np.uint8)\n",
        "        ret = np.zeros([1,28,28])\n",
        "        if ch == 1:\n",
        "            ret = ret.reshape(h, w)\n",
        "        return ret\n",
        "\n",
        "    #Load dataset from sklearn\n",
        "    def load_dataset_from_sklearn(self, dataset='test', path_data='', path_labels=''):\n",
        "        data = []\n",
        "        labels = []\n",
        "        data_reshaped = []\n",
        "        if(not(path_data == '' or path_labels == '')):\n",
        "            data = np.load(path_data, allow_pickle=True)\n",
        "            labels = np.load(path_labels, allow_pickle=True)\n",
        "            print('Loaded dataset from file system')\n",
        "        else:\n",
        "            from sklearn.datasets import fetch_openml\n",
        "            print(\"Downloading MNIST \"+dataset+\" set from sklearn\")\n",
        "            data, labels = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "            data_reshaped = data.reshape(-1, 1, 28, 28).transpose(0, 1, 3, 2)\n",
        "            np.save('data', data)\n",
        "            np.save('labels', labels)\n",
        "            print((\"done\"))\n",
        "        if (dataset == 'training'):\n",
        "            return data[:60000], data_reshaped[:60000] / np.float32(255), labels[:60000]\n",
        "        return data[-10000:], data_reshaped[-10000:] / np.float32(255), labels[-10000:]\n",
        "\n",
        "    def perform_tSNE(self, data, path_tSNE=''):\n",
        "        img_embed = None\n",
        "        if(self.path_tSNE==''):\n",
        "                print(\"Performing t-SNE on a dataset of shape \"+str(data.shape)+\"...\")\n",
        "                tsne = TSNE(n_components=2)\n",
        "                img_embed = tsne.fit_transform(data)\n",
        "                np.save(self.path_tSNE, img_embed)\n",
        "        else:\n",
        "            print(\"Loading existing t-SNE embedding from file system\")\n",
        "            img_embed = np.load(self.path_tSNE)\n",
        "            print(\"done\")\n",
        "        return img_embed\n",
        "    \n",
        "    def perform_KMeans(self, embedding, labels, n_clusters):\n",
        "        print(\"Performing KMeans. K =\",n_clusters)\n",
        "        clusters_dimension = [0]*n_clusters\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(embedding)\n",
        "        distances = KMeans(n_clusters=n_clusters, random_state=0).fit_transform(embedding)\n",
        "        for i in kmeans.labels_:\n",
        "                clusters_dimension[i]+=1\n",
        "        clusters = [ [] for i in range(n_clusters)]\n",
        "        pos = 0\n",
        "        for i in kmeans.labels_:\n",
        "                clusters[i].append(Number(embedding[pos][0], embedding[pos][1], pos, labels[pos]))\n",
        "                pos+=1\n",
        "\n",
        "        med = np.argmin(distances, axis=0)\n",
        "        clusters_others = {}\n",
        "        for i in range(len(clusters)):\n",
        "            cluster = clusters[i]\n",
        "            medoid = med[i]\n",
        "            others = [x.get_index() for x in cluster if x.get_val()!=str(labels[medoid])]\n",
        "            clusters_others[medoid]=others\n",
        "\n",
        "        return clusters, clusters_others\n",
        "\n",
        "        \n",
        "\n",
        "    def generate_moving_mnist(self, \n",
        "                              dataset='test', \n",
        "                              shape=(64, 64), \n",
        "                              num_frames=20, \n",
        "                              num_sequences=10000, \n",
        "                              original_size=28,\n",
        "                              nums_per_image=2):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "        dataset = {test, training}: used to decide if downloading/generating train set or test set\n",
        "        shape: Shape we want for our moving images (new_width and new_height)\n",
        "        num_frames: Number of frames in a particular movement/animation/gif\n",
        "        num_sequences: Number of movement/animations/gif to generate\n",
        "        original_size: Real size of the images (eg: MNIST is 28x28)\n",
        "        nums_per_image: Digits per movement/animation/gif.\n",
        "\n",
        "        Returns:\n",
        "        Dataset of np.uint8 type with dimensions num_frames * num_sequences x 1 x new_width x new_height\n",
        "\n",
        "        '''\n",
        "        if(self.dataset == 'training'):\n",
        "            print(\"Generating training set of shape (\"+str(num_sequences)+\", \"+\n",
        "                  str(num_frames)+\", 1, \"+str(shape[0])+\", \"+str(shape[1])+\")\")\n",
        "        else:\n",
        "            print(\"Generating test set of shape (\"+str(num_sequences)+\", \"+\n",
        "                  str(num_frames)+\", 1, \"+str(shape[0])+\", \"+str(shape[1])+\")\")\n",
        "            \n",
        "        data, mnist, labels = self.load_dataset_from_sklearn(self.dataset, \n",
        "                                                                path_data=self.path_data,\n",
        "                                                                 path_labels=self.path_labels)\n",
        "        \n",
        "        img_embed = self.perform_tSNE(data, self.path_tSNE)\n",
        "        _, med_other = self.perform_KMeans(img_embed, labels, n_clusters=self.n_clusters)\n",
        "        '''\n",
        "        index_list = medoids\n",
        "        index_list_false = candidates\n",
        "        mnist_false = data[index_list_false].reshape(-1, 1, 28, 28)#.transpose(0, 1, 3, 2)\n",
        "        '''\n",
        "        mnist = data.reshape(-1, 1, 28, 28)#.transpose(0, 1, 3, 2)\n",
        "        \n",
        "        print(\"Building dataset...\")\n",
        "        width, height = shape\n",
        "        # Get how many pixels can we move around a single image\n",
        "        lims = (x_lim, y_lim) = width - original_size, height - original_size\n",
        "\n",
        "        # Create a dataset of shape of num_frames * num_sequences x 1 x new_width x new_height\n",
        "        # Eg : 3000000 x 1 x 64 x 64\n",
        "        dataset = np.empty((num_frames * num_sequences, 1, width, height), dtype=np.uint8)\n",
        "\n",
        "        for img_idx in range(num_sequences):\n",
        "            direcs = np.pi * (np.random.rand(nums_per_image) * 2 - 1)\n",
        "            speeds = np.random.randint(5, size=nums_per_image) + 2\n",
        "            veloc = np.asarray(\n",
        "                [(speed * math.cos(direc), speed * math.sin(direc)) for direc, speed in zip(direcs, speeds)])\n",
        "            \n",
        "            # Get a list containing two PIL images randomly sampled from the database\n",
        "            #casual_index = np.random.randint(0, mnist.shape[0], nums_per_image)\n",
        "            casual_index = np.random.randint(0, self.n_clusters, nums_per_image)\n",
        "            mnist_images = []\n",
        "            image_false = None\n",
        "            mnist_images_false = None\n",
        "            medoids = list(med_other.keys())\n",
        "\n",
        "            for r in casual_index:\n",
        "                mnist_images.append(Image.fromarray(self.get_image_from_array(mnist, medoids[r], mean=0)).resize((original_size, original_size), Image.ANTIALIAS))\n",
        "            \n",
        "            anom_list_med_1 = med_other[medoids[casual_index[0]]]\n",
        "            anom_list_med_2 = med_other[medoids[casual_index[1]]]\n",
        "            np.random.shuffle(anom_list_med_1)\n",
        "            np.random.shuffle(anom_list_med_2)\n",
        "            anom_index_1 = anom_list_med_1[0]\n",
        "            anom_index_2 = anom_list_med_2[0]\n",
        "            image_false1 = Image.fromarray(self.get_image_from_array(mnist, anom_index_1, mean=0)).resize((original_size, original_size), Image.ANTIALIAS)\n",
        "            image_false2 = Image.fromarray(self.get_image_from_array(mnist, anom_index_2, mean=0)).resize((original_size, original_size), Image.ANTIALIAS)\n",
        "            \n",
        "            if(self.num_anoms_per_frame == 1):\n",
        "                rand_idx = np.random.randint(2)\n",
        "                mnist_images_false = [image_false1, image_false2]\n",
        "                mnist_images_false[rand_idx] = mnist_images[rand_idx]\n",
        "\n",
        "            if(self.num_anoms_per_frame == 2):\n",
        "                mnist_images_false = [image_false1, image_false2]\n",
        "\n",
        "            # Generate tuples of (x,y) i.e initial positions for nums_per_image (default : 2)\n",
        "            positions = np.asarray(\n",
        "                [(np.random.rand() * x_lim, np.random.rand() * y_lim) for _ in range(nums_per_image)])\n",
        "            positions_false = np.asarray(\n",
        "                [(np.random.rand() * x_lim, np.random.rand() * y_lim) for _ in range(nums_per_image)])\n",
        "\n",
        "            # Generate new frames for the entire num_framesgth\n",
        "            for frame_idx in range(num_frames):\n",
        "                canvases = [Image.new('L', (width, height)) for _ in range(nums_per_image)]\n",
        "                canvas = np.zeros((1, width, height), dtype=np.float32)\n",
        "\n",
        "                # In canv (i.e Image object) place the image at the respective positions\n",
        "                # Super impose both images on the canvas (i.e empty np array)\n",
        "                for i, canv in enumerate(canvases):\n",
        "                    im = mnist_images[i]\n",
        "                    if(frame_idx in self.anom_frames):\n",
        "                        im = mnist_images_false[i]    \n",
        "                        #canv.paste(im, tuple(positions_false[i].astype(int)))\n",
        "                    #else:    \n",
        "                    canv.paste(im, tuple(positions[i].astype(int)))\n",
        "                    canvas += self.arr_from_img(canv, mean=0)\n",
        "\n",
        "                # Get the next position by adding velocity\n",
        "                next_pos = positions + veloc\n",
        "\n",
        "                # Iterate over velocity and see if we hit the wall\n",
        "                # If we do then change the  (change direction)\n",
        "                for i, pos in enumerate(next_pos):\n",
        "                    for j, coord in enumerate(pos):\n",
        "                        if coord < -2 or coord > lims[j] + 2:\n",
        "                            veloc[i] = list(list(veloc[i][:j]) + [-1 * veloc[i][j]] + list(veloc[i][j + 1:]))\n",
        "\n",
        "                # Make the permanent change to position by adding updated velocity\n",
        "                positions = positions + veloc\n",
        "\n",
        "                # Add the canvas to the dataset array\n",
        "                dataset[img_idx * num_frames + frame_idx] = ((canvas).clip(0, 255)).astype(np.float32)\n",
        "        #Reshape dataset to have a shape like (30, 100, 1, 64, 64)\n",
        "        dataset = dataset.reshape(num_sequences, num_frames, 1, width, height)\n",
        "        print(\"done! :)\")\n",
        "        return dataset\n",
        "\n",
        "    def generate_ano_mnist(self):\n",
        "        shape = self.shape\n",
        "        num_frames = self.num_frames\n",
        "        num_sequences = self.num_sequences\n",
        "        original_size = self.original_size\n",
        "        nums_per_image = self.nums_per_image\n",
        "        dat = self.generate_moving_mnist(dataset='test', shape=shape, num_frames=num_frames, num_sequences=num_sequences,\n",
        "                                original_size=original_size, nums_per_image=nums_per_image)\n",
        "\n",
        "        n = num_sequences * num_frames\n",
        "        if self.filetype == 'npz':\n",
        "            np.savez(self.dest, anommnist=dat)\n",
        "        elif filetype == 'jpg':\n",
        "            for i in range(dat.shape[0]):\n",
        "                Image.fromarray(self.get_image_from_array(dat, i, mean=0)).save(os.path.join(dest, '{}.jpg'.format(i)))\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PjIPbFKoTgb",
        "colab_type": "code",
        "outputId": "f141e6a0-2ef2-418b-aa46-27b9565b5911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "gen = AnomalousMovingMNIST(\n",
        "    anom_frames=[5],\n",
        "    num_anoms_per_frame=1,\n",
        "    type_of_anomaly = None,\n",
        "    num_frames=20, \n",
        "    num_sequences=200, \n",
        "    dataset = 'test', \n",
        "    path_data='data.npy', \n",
        "    path_labels='labels.npy', \n",
        "    path_tSNE='tsne.npy', \n",
        "    dest='anommnist')\n",
        "\n",
        "gen.generate_ano_mnist()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating test set of shape (200, 20, 1, 64, 64)\n",
            "Loaded dataset from file system\n",
            "Loading existing t-SNE embedding from file system\n",
            "done\n",
            "Performing KMeans. K = 30\n",
            "Building dataset...\n",
            "done! :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoPrVjyl8mYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "dat = np.load('anommnist.npz')['anommnist']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t8zuars8vwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7afb2ab0-221a-4276-85ba-3cf8813aac9f"
      },
      "source": [
        "seq = 110\n",
        "plt.imshow(dat[seq,4,0,])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fece45368d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3vD8eoe-Y0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "3bde08b2-5a30-4525-e1e5-4bc29d23aabf"
      },
      "source": [
        "plt.imshow(dat[seq,5,0,])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fece449b438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYjdLxP8DmEbjTHh0JVYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RwWVzizopAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimilarFrame:\n",
        "    def perform():\n",
        "        pass\n",
        "\n",
        "class CasualFrame:\n",
        "    def perform():\n",
        "        pass\n",
        "\n",
        "class BlurredFrame:\n",
        "    def perform():\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}