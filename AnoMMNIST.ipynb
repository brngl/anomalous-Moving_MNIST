{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnoMMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWw-wWgrqO2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Number:\n",
        "    def __init__(self, x, y, index, val):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.index = index\n",
        "        self.val = val\n",
        "\n",
        "    def get_x(self):\n",
        "        return self.x\n",
        "\n",
        "    def get_y(self):\n",
        "        return self.y\n",
        "\n",
        "    def get_index(self):\n",
        "        return self.index\n",
        "\n",
        "    def get_val(self):\n",
        "        return self.val\n",
        "\n",
        "    def distance(self, point):\n",
        "        # Euclidean distance beetween this point and other\n",
        "        import math\n",
        "        return math.sqrt(abs(self.get_x() - point.get_x()) + abs(self.get_y() - point.get_y()))\n",
        "\n",
        "    def encapsulate_numbers(legend_array, img_embed):\n",
        "        numbers = []\n",
        "        for i in range(len(legend_array)):\n",
        "            x_coo = img_embed[i,:][0]\n",
        "            y_coo = img_embed[i,:][1]\n",
        "            number = Number(x_coo, y_coo, i, legend_array[i])\n",
        "            numbers.append(number)\n",
        "        return numbers\n",
        "\n",
        "\n",
        "    def neighbours(numbers, same_digit, neighbourhood):\n",
        "        \"\"\"\n",
        "        # same_digit: a boolean. If False, it searches for different numbers who look like similar.\n",
        "                                If True, it searches for two similar representations of the same number.\n",
        "        # neighbourhood: a tuple. (min_distance, max_distance). min_distance xor max_distance can be None.\n",
        "        \"\"\"\n",
        "        min_distance = neighbourhood[0]\n",
        "        max_distance = neighbourhood[1]\n",
        "\n",
        "        if (min_distance == None and max_distance == None):\n",
        "            raise ValueError(\"Just one beetween min_distance and max_distance can be None\")\n",
        "\n",
        "        if (min_distance != None):\n",
        "            min_distance = neighbourhood[0]\n",
        "        else:\n",
        "            min_distance = 0\n",
        "\n",
        "        if (max_distance != None):\n",
        "            max_distance = neighbourhood[1]\n",
        "        else:\n",
        "            max_distance = 5\n",
        "\n",
        "        nbs = []\n",
        "        for num1 in numbers:\n",
        "            if (num1.get_index() % 1000 == 0):\n",
        "                print(num1.get_index())\n",
        "            for num2 in numbers:\n",
        "                same = True\n",
        "                if (not same_digit):\n",
        "                    same = num1.get_val() != num2.get_val()\n",
        "                else:\n",
        "                    same = num1.get_val() == num2.get_val()\n",
        "                if (num1.get_index() != num2.get_index() and\n",
        "                        min_distance <= num1.distance(num2) <= max_distance and\n",
        "                        same):\n",
        "                    nbs.append((num1, num2))\n",
        "        return nbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGmvJiIRfwXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "class AnomalousMovingMNIST:\n",
        "    '''\n",
        "    Args:\n",
        "            anom_frames: list of anomalous frame indexes that must appear in the sequence\n",
        "            num_anoms_per_frame: how many MNIST numbers have to be anomalous in an anomalous frame\n",
        "            n_clusters: number of clusters to perform K-Means. \n",
        "                More clusters imply smaller cluster size, more similarity between instances but less variety.\n",
        "                Less clusters imply bigger cluster size, less similarity between instances but more variety.\n",
        "            dataset = {training, test}: specifies whether the dataset should be created from the MNIST training set or test set\n",
        "    '''\n",
        "    def __init__(self, \n",
        "                 anom_frames,\n",
        "                 num_anoms_per_frame,\n",
        "                 num_sequences=20000,\n",
        "                 shape=(64, 64),\n",
        "                 num_frames=30,\n",
        "                 original_size=28,\n",
        "                 nums_per_image=2,\n",
        "                 path_data = '',\n",
        "                 path_labels = '',\n",
        "                 path_tSNE = '',\n",
        "                 n_clusters = 30,\n",
        "                 dest='anomovingmnistdata',\n",
        "                 filetype='npz',\n",
        "                 dataset='test',):\n",
        "        if(not num_anoms_per_frame in [1,2]):\n",
        "            raise ValueError(\"num_anoms_per_frame must be 1 or 2\")\n",
        "        \n",
        "        if(not dataset in ['training', 'test']):\n",
        "            raise ValueError(\"possible values: {training, test}\")\n",
        "        \n",
        "        self.shape = shape\n",
        "        self.num_frames = num_frames\n",
        "        self.num_sequences = num_sequences\n",
        "        self.original_size = original_size\n",
        "        self.nums_per_image = nums_per_image\n",
        "        self.dest = dest\n",
        "        self.filetype = filetype\n",
        "        self.dataset = dataset\n",
        "        self.path_data = path_data\n",
        "        self.path_labels = path_labels\n",
        "        self.path_tSNE = path_tSNE\n",
        "        self.n_clusters = n_clusters\n",
        "        self.anom_frames = anom_frames\n",
        "        self.num_anoms_per_frame = num_anoms_per_frame\n",
        "\n",
        "    def get_mnist_path(self):\n",
        "        return self.mnist_path\n",
        "    \n",
        "    def arr_from_img(self, im, mean=0, std=1):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            im: Image\n",
        "            shift: Mean to subtract\n",
        "            std: Standard Deviation to subtract\n",
        "\n",
        "        Returns:\n",
        "            Image in np.float32 format, in width height channel format. With values in range 0,1\n",
        "            Shift means subtract by certain value. Could be used for mean subtraction.\n",
        "        '''\n",
        "        width, height = im.size\n",
        "        arr = im.getdata()\n",
        "        c = int(np.product(arr.size) / (width * height))\n",
        "\n",
        "        return (np.asarray(arr, dtype=np.float32).reshape((height, width, c)).transpose(2, 1, 0)) / std\n",
        "\n",
        "    def get_image_from_array(self, X, index, mean=0, std=1):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            X: Dataset of shape N x C x W x H\n",
        "            index: Index of image we want to fetch\n",
        "            mean: Mean to add\n",
        "            std: Standard Deviation to add\n",
        "        Returns:\n",
        "            Image with dimensions H x W x C or H x W if it's a single channel image\n",
        "        '''\n",
        "        ch, w, h = X.shape[1], X.shape[2], X.shape[3]\n",
        "        ret = (((X[index] + mean)) * std).reshape(ch, w, h).transpose(2, 1, 0)#.clip(0, 255).astype(np.uint8)\n",
        "        if ch == 1:\n",
        "            ret = ret.reshape(h, w)\n",
        "        return ret\n",
        "\n",
        "    def get_image_from_array_blank(self, X, index, mean=0, std=1):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            X: Dataset of shape N x C x W x H\n",
        "            index: Index of image we want to fetch\n",
        "            mean: Mean to add\n",
        "            std: Standard Deviation to add\n",
        "        Returns:\n",
        "            Image with dimensions H x W x C or H x W if it's a single channel image\n",
        "        '''\n",
        "        ch, w, h = X.shape[1], X.shape[2], X.shape[3]\n",
        "        ret = (((X[index] + mean)) * std).reshape(ch, w, h).transpose(2, 1, 0)#.clip(0, 255).astype(np.uint8)\n",
        "        ret = np.zeros([1,28,28])\n",
        "        if ch == 1:\n",
        "            ret = ret.reshape(h, w)\n",
        "        return ret\n",
        "\n",
        "    #Load dataset from sklearn\n",
        "    def load_dataset_from_sklearn(self, dataset='test', path_data='', path_labels=''):\n",
        "        data = []\n",
        "        labels = []\n",
        "        data_reshaped = []\n",
        "        if(not(path_data == '' or path_labels == '')):\n",
        "            data = np.load(path_data, allow_pickle=True)\n",
        "            labels = np.load(path_labels, allow_pickle=True)\n",
        "            print('Loaded dataset from file system')\n",
        "        else:\n",
        "            from sklearn.datasets import fetch_openml\n",
        "            print(\"Downloading MNIST \"+dataset+\" set from sklearn\")\n",
        "            data, labels = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "            data_reshaped = data.reshape(-1, 1, 28, 28).transpose(0, 1, 3, 2)\n",
        "            np.save('data', data)\n",
        "            np.save('labels', labels)\n",
        "            print((\"done\"))\n",
        "        if (dataset == 'training'):\n",
        "            return data[:60000], data_reshaped[:60000] / np.float32(255), labels[:60000]\n",
        "        return data[-10000:], data_reshaped[-10000:] / np.float32(255), labels[-10000:]\n",
        "\n",
        "    def perform_tSNE(self, data, path_tSNE=''):\n",
        "        img_embed = None\n",
        "        if(self.path_tSNE==''):\n",
        "                print(\"Performing t-SNE on a dataset of shape \"+str(data.shape)+\"...\")\n",
        "                tsne = TSNE(n_components=2)\n",
        "                img_embed = tsne.fit_transform(data)\n",
        "                np.save(self.path_tSNE, img_embed)\n",
        "        else:\n",
        "            print(\"Loading existing t-SNE embedding from file system\")\n",
        "            img_embed = np.load(self.path_tSNE)\n",
        "            print(\"done\")\n",
        "        return img_embed\n",
        "    \n",
        "    def perform_KMeans(self, embedding, labels, n_clusters):\n",
        "        print(\"Performing KMeans. K =\",n_clusters)\n",
        "        clusters = {}\n",
        "        clusters_dimension = [0]*n_clusters\n",
        "        medoids = []\n",
        "        candidates = []\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(embedding)\n",
        "        distances = KMeans(n_clusters=n_clusters, random_state=0).fit_transform(embedding)\n",
        "        for i in kmeans.labels_:\n",
        "                clusters_dimension[i]+=1\n",
        "        clusters = [ [] for i in range(n_clusters)]\n",
        "        pos = 0\n",
        "        for i in kmeans.labels_:\n",
        "                clusters[i].append(Number(embedding[pos][0], embedding[pos][1], pos, labels[pos]))\n",
        "                pos+=1\n",
        "        \n",
        "        \n",
        "        for k in range(distances.shape[1]):\n",
        "            arr = distances[:, k] \n",
        "            min_dist = 10000000\n",
        "            med = 0\n",
        "            for i in range(distances.shape[0]):\n",
        "                if(arr[i] < min_dist):\n",
        "                    min_dist = arr[i]\n",
        "                    med = i\n",
        "            medoids.append(med)\n",
        "        candidates = []\n",
        "        for i in range(n_clusters):\n",
        "            cli = clusters[i]\n",
        "            #index_false = np.random.randint(0, len(cli))\n",
        "            index_candidates=0\n",
        "            found = True\n",
        "            while(index_candidates < len(cli)-1 and (index_candidates == medoids[i] or labels[medoids[i]] == cli[index_candidates].get_val())):\n",
        "                index_candidates+=1\n",
        "                #index_false = np.random.randint(0, len(cli))\n",
        "            while(index_candidates == medoids[i] and index_candidates >= len(cli)):\n",
        "            #while(index_false == candidates_true[i] or index_false >= len(cli)):\n",
        "                index_candidates = np.random.randint(0, len(cli)-1)\n",
        "            candidates.append(cli[index_candidates].get_index())\n",
        "\n",
        "        return clusters, medoids, candidates\n",
        "\n",
        "        \n",
        "\n",
        "    def generate_moving_mnist(self, dataset='test', shape=(64, 64), num_frames=20, num_sequences=10000, original_size=28,\n",
        "                              nums_per_image=2):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            dataset = {test, training}: used to decide if downloading/generating train set or test set\n",
        "            shape: Shape we want for our moving images (new_width and new_height)\n",
        "            num_frames: Number of frames in a particular movement/animation/gif\n",
        "            num_sequences: Number of movement/animations/gif to generate\n",
        "            original_size: Real size of the images (eg: MNIST is 28x28)\n",
        "            nums_per_image: Digits per movement/animation/gif.\n",
        "\n",
        "        Returns:\n",
        "            Dataset of np.uint8 type with dimensions num_frames * num_sequences x 1 x new_width x new_height\n",
        "\n",
        "        '''\n",
        "        if(self.dataset == 'training'):\n",
        "            print(\"Generating training set of shape (\"+str(num_sequences)+\", \"+\n",
        "                  str(num_frames)+\", 1, \"+str(shape[0])+\", \"+str(shape[1])+\")\")\n",
        "        else:\n",
        "            print(\"Generating test set of shape (\"+str(num_sequences)+\", \"+\n",
        "                  str(num_frames)+\", 1, \"+str(shape[0])+\", \"+str(shape[1])+\")\")\n",
        "            \n",
        "        data, mnist, labels = self.load_dataset_from_sklearn(self.dataset, \n",
        "                                                                path_data=self.path_data,\n",
        "                                                                 path_labels=self.path_labels)\n",
        "        \n",
        "        img_embed = self.perform_tSNE(data, self.path_tSNE)\n",
        "        _, medoids, candidates = self.perform_KMeans(img_embed, labels, n_clusters=self.n_clusters)\n",
        "\n",
        "        index_list = medoids\n",
        "        index_list_false = candidates\n",
        "        mnist_false = data[index_list_false].reshape(-1, 1, 28, 28)#.transpose(0, 1, 3, 2)\n",
        "        mnist = data[index_list].reshape(-1, 1, 28, 28)#.transpose(0, 1, 3, 2)\n",
        "\n",
        "        print(\"Building dataset...\")\n",
        "        width, height = shape\n",
        "        # Get how many pixels can we move around a single image\n",
        "        lims = (x_lim, y_lim) = width - original_size, height - original_size\n",
        "\n",
        "        # Create a dataset of shape of num_frames * num_sequences x 1 x new_width x new_height\n",
        "        # Eg : 3000000 x 1 x 64 x 64\n",
        "        dataset = np.empty((num_frames * num_sequences, 1, width, height), dtype=np.uint8)\n",
        "        for img_idx in range(num_sequences):\n",
        "            direcs = np.pi * (np.random.rand(nums_per_image) * 2 - 1)\n",
        "            speeds = np.random.randint(5, size=nums_per_image) + 2\n",
        "            veloc = np.asarray(\n",
        "                [(speed * math.cos(direc), speed * math.sin(direc)) for direc, speed in zip(direcs, speeds)])\n",
        "            # Get a list containing two PIL images randomly sampled from the database\n",
        "            casual_index = np.random.randint(0, mnist.shape[0], nums_per_image)\n",
        "            mnist_images = []\n",
        "            image_false = None\n",
        "            mnist_images_false = None\n",
        "\n",
        "            for r in casual_index:\n",
        "                mnist_images.append(Image.fromarray(self.get_image_from_array(mnist, r, mean=0)).resize((original_size, original_size),\n",
        "                                                                               Image.ANTIALIAS))\n",
        "            \n",
        "            index_to_false1 = casual_index[0]\n",
        "            index_to_false2 = casual_index[1]\n",
        "            image_false1 = Image.fromarray(self.get_image_from_array(mnist_false, index_to_false1, mean=0)).resize((original_size, original_size),\n",
        "                                                                            Image.ANTIALIAS)\n",
        "            image_false2 = Image.fromarray(self.get_image_from_array(mnist_false, index_to_false2, mean=0)).resize((original_size, original_size),\n",
        "                                                                            Image.ANTIALIAS)\n",
        "            \n",
        "            if(self.num_anoms_per_frame == 1):\n",
        "                rand_idx = np.random.randint(2)\n",
        "                mnist_images_false = [image_false1, image_false2]\n",
        "                mnist_images_false[rand_idx] = mnist_images[rand_idx]\n",
        "\n",
        "            if(self.num_anoms_per_frame == 2):\n",
        "                mnist_images_false = [image_false1, image_false2]\n",
        "\n",
        "            # Generate tuples of (x,y) i.e initial positions for nums_per_image (default : 2)\n",
        "            positions = np.asarray(\n",
        "                [(np.random.rand() * x_lim, np.random.rand() * y_lim) for _ in range(nums_per_image)])\n",
        "            positions_false = np.asarray(\n",
        "                [(np.random.rand() * x_lim, np.random.rand() * y_lim) for _ in range(nums_per_image)])\n",
        "\n",
        "            # Generate new frames for the entire num_framesgth\n",
        "            for frame_idx in range(num_frames):\n",
        "                canvases = [Image.new('L', (width, height)) for _ in range(nums_per_image)]\n",
        "                canvas = np.zeros((1, width, height), dtype=np.float32)\n",
        "\n",
        "                # In canv (i.e Image object) place the image at the respective positions\n",
        "                # Super impose both images on the canvas (i.e empty np array)\n",
        "                for i, canv in enumerate(canvases):\n",
        "                    im = mnist_images[i]\n",
        "                    if(frame_idx in self.anom_frames):\n",
        "                        im = mnist_images_false[i]    \n",
        "                        #canv.paste(im, tuple(positions_false[i].astype(int)))\n",
        "                    #else:    \n",
        "                    canv.paste(im, tuple(positions[i].astype(int)))\n",
        "                    canvas += self.arr_from_img(canv, mean=0)\n",
        "\n",
        "                # Get the next position by adding velocity\n",
        "                next_pos = positions + veloc\n",
        "\n",
        "                # Iterate over velocity and see if we hit the wall\n",
        "                # If we do then change the  (change direction)\n",
        "                for i, pos in enumerate(next_pos):\n",
        "                    for j, coord in enumerate(pos):\n",
        "                        if coord < -2 or coord > lims[j] + 2:\n",
        "                            veloc[i] = list(list(veloc[i][:j]) + [-1 * veloc[i][j]] + list(veloc[i][j + 1:]))\n",
        "\n",
        "                # Make the permanent change to position by adding updated velocity\n",
        "                positions = positions + veloc\n",
        "\n",
        "                # Add the canvas to the dataset array\n",
        "                dataset[img_idx * num_frames + frame_idx] = ((canvas).clip(0, 255)).astype(np.float32)\n",
        "        #Reshape dataset to have a shape like (30, 100, 1, 64, 64)\n",
        "        dataset = dataset.reshape(num_sequences, num_frames, 1, width, height)\n",
        "        print(\"done! :)\")\n",
        "        return dataset\n",
        "\n",
        "    def generate_ano_mnist(self):\n",
        "        shape = self.shape\n",
        "        num_frames = self.num_frames\n",
        "        num_sequences = self.num_sequences\n",
        "        original_size = self.original_size\n",
        "        nums_per_image = self.nums_per_image\n",
        "        dat = self.generate_moving_mnist(dataset='test', shape=shape, num_frames=num_frames, num_sequences=num_sequences,\n",
        "                                original_size=original_size, nums_per_image=nums_per_image)\n",
        "\n",
        "        n = num_sequences * num_frames\n",
        "        if self.filetype == 'npz':\n",
        "            np.savez(self.dest, anommnist=dat)\n",
        "        elif filetype == 'jpg':\n",
        "            for i in range(dat.shape[0]):\n",
        "                Image.fromarray(self.get_image_from_array(dat, i, mean=0)).save(os.path.join(dest, '{}.jpg'.format(i)))\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PjIPbFKoTgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "30aea51e-e563-4a12-c128-48aeebec7bbf"
      },
      "source": [
        "gen = AnomalousMovingMNIST(\n",
        "    anom_frames=[5,6,7],\n",
        "    num_anoms_per_frame=1,\n",
        "    num_frames=20, \n",
        "    num_sequences=200, \n",
        "    dataset = 'test', \n",
        "    path_data='data.npy', \n",
        "    path_labels='labels.npy', \n",
        "    path_tSNE='tsne.npy', \n",
        "    dest='anommnist')\n",
        "\n",
        "gen.generate_ano_mnist()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating test set of shape (200, 20, 1, 64, 64)\n",
            "Loaded dataset from file system\n",
            "Loading existing t-SNE embedding from file system\n",
            "done\n",
            "Performing KMeans. K = 30\n",
            "Building dataset...\n",
            "done! :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWv3YUAtqz_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "an = np.load('anommnist.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek3_9_fg6Hu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "an = an['anommnist']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynOiwEk06LrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d12eee56-3ea5-45ae-c1cf-11fbaf2cf8de"
      },
      "source": [
        "an.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 20, 1, 64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VPVpQDQ6OOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOeNKQGb6ZA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "ae320b5f-4046-4bc2-f882-07c45435a93e"
      },
      "source": [
        "plt.imshow(an[111,7,0,...], cmap = plt.cm.gray)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8eb46e44a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNEpfd5o6dFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "add53e46-12c4-47e2-d609-c695d6a644f8"
      },
      "source": [
        "plt.imshow(an[111,8,0,...], cmap = plt.cm.gray)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8eb464a240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ0fSE6HvCwMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2l4oMWF7eE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}